\chapter{Literature Review}

\section{Literature Overview}
This chapter will discuss existing literature relating to the \gls{ta} protocol. A discussion of the use of Experience as a metric within the testing of applications, especially in relation to \gls{ta} studies will also be discussed.
\section{The Think-Aloud Methodology}
The Think- Aloud protocol (TA) is a form of usability testing whereby test participants are told to verbally communicate there thoughts during tasks of a usability study, or simply to ``think aloud". This could be during the experiment where test organisers would ask participants to verbalise their thought process during the participants attempt to complete tasks, this is refereed to as ``concurrent usability testing" (CTA). Additionally there is also the notion of ``retrospective think-aloud" (RTA) methods, where test participants complete tasks and then verbalise there thought process after the tasks are complete. The concept of Think-Aloud has been developed by Ericsson and Simon, in which they classify three levels of verbalisation \citep{ericsson1998study}. Levels 1 and 2 are the most useful types of data, according to Ericsson and Simon. Type 3 data makes assumptions on how the user infers a task, which could make collected data unreliable. An example they give is to ask users to select only certain items to a criteria, therefore asking users to filter items, which requires some inference on the users part. However as Boren and Ramey writes, the way in which a speaker relays their interpretation of tasks in also influenced by the accompanying practitioner. For instance if a speaker has the expectation of a response from the listening practitioner, but does not receive a response, it could skew their response in a number of different ways.\citep{boren2000thinking}. Therefore TA practitioners should be careful when providing explanations to study participants, to help minimise these potential effects.

These methods have been analysed by various studies comparing variations of Think-Aloud for there associated strengths and weaknesses. Issues have been highlighted by Ramey et al. One issue could include the potential for distraction as some participants may find it difficult to both verbalise there thought processes when attempting tasks during a CTA study, as participants could be influenced by CTA by taking longer to complete tasks, or being unable to complete tasks overall as they cannot concentrate \citep{ramey2006does}. This view is also shared in a 2013 study, although McDonald's et al findings did not find that to be of determent in all their participants. \citep{mcdonald2013thinking}. However many studies argue that by thinking aloud, knowledge on how participants feel in the task can be easily explained in what they say, and how they say it. As Cooke comments, CTA in combination with eye tracking software produces reliable and useful data in how users interact with websites \citep{cooke2010assessing}, as what people say can be verified by the recorded location of their eyes during a CTA test. In a 1991 study, Think-aloud methods were seen to be useful for UX designers as they detect issues that the designers themselves could not detect \citep{wright1991cost}.This has been seen in more recent studies including Van et al, in which they conclude that retrospective and concurrent usability testing leads to the discovery of similar issues, but in different ways \citep{van2000thinking} and \citep{van2003retrospective}. 


\section{Experience as a Metric in Usability Studies}
There has been other studies conducted on that of the user experience, this is in terms of how valid users of different experience levels can be used, and if these groups should be used to test different tasks. This is on the basis that novices and experienced users have prerequisite requirements such as a lack of knowledge in the tested application (for novices), and a minimum level of knowledge for experts. \citep{popovic2000expert}.In several previous studies, novice and expert users were often given different tasks. Faulkner and Wick state that, in "traditional usability testing" a users experience was used to measure different tasks, novice users were useful in determining a programs learnability and experienced users were used to find the most optimal outcome.\citep{faulkner2005cross} However they argue that by using both novices and experts for the same research tasks could lead to more useful data. They also explicitly refer to the flaws of not using multiple levels of experience in detecting flaws in a program, making reference to the "Therac-25" incidents. Therac-25 was a medical accelerator used for radiation therapy, but was also the cause of several patient deaths due to radiation overdoses. One such reason for these overdoses was due to the speed in which experienced users were able to enter commands for the system to process, however as they were familiar with the process they entered the commands too quickly for the Therac-25 system to assimilate. Faulkner and Wick suggest that by employing both novice and expert users, issues such as this could potentially have been detected, although they do not fully explain why, and more concrete examples were absent from this study.

 Novice and expert users have also been used in tests between two distinct versions of a program. For instance, on study focused on two versions of software of a university database dedicated to art resources. The first version had graphical aids, and the second had no graphics elements. The general results showed that novice users improved their ability to use the tested program with presence of graphical cues, versus that with without \citep{dillon1997empirical}. Expert users involved in the study however showed that there was little difference in how effectively they were able to use the program. Therefore if novices were absent from the test this information would not be present at all. The factor of task completion time has also been studied in experience based experiments, including the Novice Expert Ratio method (NEM) method. This methodology concluded that if there was a significant difference of task completion time between novice and expert users, the service being used has usability issues.\citep{urokohara2000nem} Although this can be the case, the issue of familiarity arises. Should a user who is a novice spend more time with a service or product the number of issues they have with a service would decrease, and therefore this metric alone does not necessarily indicate an issue with the product.

